{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# RAG\n",
    "> Retrival Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Expert Knowledge Worker\n",
    "- A Question Answering agent that is an expert in Knowledge Worker\n",
    "- To be used for employees of `Insurellm`, an Insurance Tech Company.\n",
    "- The agent needs to be accurate and the cost should be low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\Git-hub\\LLM-engieering\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our api key as well as creating openai client for our model\n",
    "try:\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv('SAMBANOVA_API_KEY')\n",
    "    try:\n",
    "        client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://api.sambanova.ai/v1\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error while creating client... TRY AGAIN: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while getting API Key... Try again: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chen\n",
      "Harper\n",
      "Thomson\n",
      "Lancaster\n",
      "Carter\n",
      "Tran\n",
      "Blake\n",
      "Bishop\n",
      "Thompson\n",
      "Spencer\n",
      "Greene\n",
      "Trenton\n"
     ]
    }
   ],
   "source": [
    "employees = glob.glob(\"knowledge-base/employees/*\")\n",
    "for emp in employees:\n",
    "    print(emp.split(\" \")[-1][:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Working of this above code.\\n1. employees = glob.glob(\"knowledge-base/emoployees/*\"): it will get all the employees file, which is saved by the employe\\'s name.\\n2. name: it will save the last name of the employee\\n3. doc = here we will store all the information about the employee\\n4. using open method for reading the employee\\'s data.\\n5. now in the end we will store the employee\\'s data in KD dict where key is last_name and value will be employee\\'s data\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating our knowledge base with bruteforce apporach\n",
    "KD = {}\n",
    "\n",
    "employees = glob.glob(\"knowledge-base/emoployees/*\")\n",
    "\n",
    "for employee in employees:\n",
    "    name = employee.split(\" \")[-1][:-3] # this will get all the emp's last name\n",
    "    doc = \"\"\n",
    "    with open(employee, 'r') as f:\n",
    "        doc = f.read()\n",
    "    KD[name]=doc\n",
    "\n",
    "\"\"\"\n",
    "# Working of this above code.\n",
    "1. employees = glob.glob(\"knowledge-base/emoployees/*\"): it will get all the employees file, which is saved by the employe's name.\n",
    "2. name: it will save the last name of the employee\n",
    "3. doc = here we will store all the information about the employee\n",
    "4. using open method for reading the employee's data.\n",
    "5. now in the end we will store the employee's data in KD dict where key is last_name and value will be employee's data\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will do the same thing with the products \n",
    "products = glob.glob(\"knowledge-base/products/*\")\n",
    "\n",
    "for product in products:\n",
    "    name = product.split(\"\\\\\")[-1][:-3]   \n",
    "    doc = \"\"\n",
    "    with open(product, 'r') as f:\n",
    "        doc = f.read()\n",
    "    KD[name]=doc\n",
    "\n",
    "# Till now in our KD dict we have collect the data for employees and product where key the product name and employee last name. and value is our document's content\n",
    "# Now our main idea is to pass the content to our llm based on the key is present or not\n",
    "# if key present pass the relevant info to the llm and let the llm generate the response based on the content from Kd and user's request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an expert in answering questions about Insurellm, the Insurance Tech company, Give brief, accurate answers. If you don't know the answer, say so. Do not make anything up if you havn't been provived with relevant context.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_info(msg):\n",
    "    relevant_info = []\n",
    "    for kd_key, kd_value in KD.items():\n",
    "        if kd_key.lower() in msg:\n",
    "            relevant_info.append(kd_value)\n",
    "    return relevant_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Product Summary\\n\\n# Carllm\\n\\n## Summary\\n\\nCarllm is an innovative auto insurance product developed by Insurellm, designed to streamline the way insurance companies offer coverage to their customers. Powered by cutting-edge artificial intelligence, Carllm utilizes advanced algorithms to deliver personalized auto insurance solutions, ensuring optimal coverage while minimizing costs. With a robust infrastructure that supports both B2B and B2C customers, Carllm redefines the auto insurance landscape and empowers insurance providers to enhance customer satisfaction and retention.\\n\\n## Features\\n\\n- **AI-Powered Risk Assessment**: Carllm leverages artificial intelligence to analyze driver behavior, vehicle conditions, and historical claims data. This enables insurers to make informed decisions and set competitive premiums that reflect true risk profiles.\\n\\n- **Instant Quoting**: With Carllm, insurance companies can offer near-instant quotes to customers, enhancing the customer experience. The AI engine processes data in real-time, drastically reducing the time it takes to generate quotes.\\n\\n- **Customizable Coverage Plans**: Carllm allows insurers to create flexible and tailored insurance packages based on individual customer needs. This customization improves customer engagement and retention.\\n\\n- **Fraud Detection**: The product incorporates advanced analytics to identify potentially fraudulent claims, significantly reducing the risk of losses for insurance providers.\\n\\n- **Customer Insights Dashboard**: Carllm provides insurers with a powerful dashboard that offers deep insights into customer behavior, claims patterns, and market trends, enabling informed decision-making and strategic planning.\\n\\n- **Mobile Integration**: Carllm is designed to work seamlessly with mobile applications, providing both insurers and end-users access to policy management and claims reporting on the go.\\n\\n- **Automated Customer Support**: Leveraging AI chatbots, Carllm offers 24/7 customer support, helping to resolve inquiries quickly and efficiently, thus improving customer satisfaction.\\n\\n## Pricing\\n\\nCarllm is offered under a subscription-based pricing model tailored to meet the needs of insurance companies of all sizes. Our pricing tiers are designed to provide maximum flexibility and value:\\n\\n- **Basic Tier**: $1,000/month\\n  - Ideal for small insurance firms.\\n  - Access to core features and standard reporting.\\n\\n- **Professional Tier**: $2,500/month\\n  - For medium-sized companies.\\n  - All Basic Tier features plus advanced analytics and fraud detection.\\n\\n- **Enterprise Tier**: $5,000/month\\n  - Customized solutions for large insurance firms.\\n  - Comprehensive support, full feature access, and integration with existing systems.\\n\\nContact our sales team for a personalized quote and discover how Carllm can transform your auto insurance offerings!\\n\\n## 2025-2026 Roadmap\\n\\nIn our commitment to continuous improvement and innovation, Insurellm has outlined the following roadmap for Carllm:\\n\\n### Q1 2025: Launch Feature Enhancements\\n- **Expanded data integrations** for better risk assessment.\\n- **Enhanced fraud detection algorithms** to reduce losses.\\n\\n### Q2 2025: Customer Experience Improvements\\n- Launch of a new **mobile app** for end-users.\\n- Introduction of **telematics-based pricing** to provide even more tailored coverage options.\\n\\n### Q3 2025: Global Expansion\\n- Begin pilot programs for international insurance markets.\\n- Collaborate with local insurers to offer compliant, localized versions of Carllm.\\n\\n### Q4 2025: AI and Machine Learning Upgrades\\n- Implement next-gen machine learning models for predictive analysis.\\n- Roll out customer insights dashboard updates based on user feedback.\\n\\n### 2026: Scaling and Partnerships\\n- Increase partnerships with automakers for integrated insurance solutions.\\n- Enhance the **AI customer support system** to include multi-language support.\\n\\nCarllm is not just an auto insurance product; it is a transformative tool for the insurance industry. Join us on this exciting journey as we redefine the future of auto insurance with technology and customer-centric solutions.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevant_info('carllm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
